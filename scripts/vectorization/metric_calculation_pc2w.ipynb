{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext line_profiler\n",
    "import h5py\n",
    "import randomcolor\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "from optimization import *\n",
    "from topological_graph import *\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.interpolate import UnivariateSpline, splev, splprep\n",
    "from scipy.optimize import minimize\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import point_cloud_utils as pcu\n",
    "import torch\n",
    "from torch_geometric.nn import fps as tfps\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import ParameterGrid \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from pytorch3d.loss.chamfer import chamfer_distance\n",
    "from geomloss import SamplesLoss\n",
    "import copy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id_it = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc_0050_00507625_b39680dc8dc650ec01956bbe_011'"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'pc2wf_res/'\n",
    "_ids = np.sort(glob('pc2wf_res/*.hdf5'))\n",
    "# _id = 'abc_0051_00514480_6c33de245ad4c4ff41a3360f_000'\n",
    "# _id = _ids[id_it].split('__')[0][6:]\n",
    "_id = _ids[id_it].split('__')[0][10:-10]\n",
    "_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['pc2wf_res/abc_0004_00041400_68770188fbbf4d658868ae7a_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0004_00046950_06d3284aaeba4d5e8eb6d441_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0005_00051130_fc39aebf81cd429e91825d67_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0005_00051370_c304c82e5c884522bb82d7af_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0005_00057780_da518f0dbee046f287c2acf5_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0050_00500041_5aa40dcd43fa0b14df9bdcf8_010_pred.hdf5',\n",
       "       'pc2wf_res/abc_0050_00500912_ded12ea6d13dadf860aaa4cb_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0050_00507625_b39680dc8dc650ec01956bbe_011_pred.hdf5',\n",
       "       'pc2wf_res/abc_0050_00508845_266ea1913e2d35805fb70e9d_001_pred.hdf5',\n",
       "       'pc2wf_res/abc_0051_00510038_1509fe78c7a4729189287091_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0051_00510073_951e25d2ded40f22b598f84e_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0051_00510118_e88bd32150a7b44caee0fd29_003_pred.hdf5',\n",
       "       'pc2wf_res/abc_0051_00510141_2b44a82f2bf7942f43634723_000_pred.hdf5',\n",
       "       'pc2wf_res/abc_0051_00510218_0539d1001509ed5da517b042_000_pred.hdf5'],\n",
       "      dtype='<U66')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### print('Processing ', _id)\n",
    "# with h5py.File('{path}/{_id}__min.hdf5'.format(path=path, _id=_id), 'r') as f:\n",
    "with h5py.File('{path}/{_id}_pred.hdf5'.format(path=path, _id=_id), 'r') as f:\n",
    "    whole_model_points = f['predictions'][:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred_sampling = np.array(whole_model_points).reshape(-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8ca64554e04954a59294a2ffc842fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save this also\n",
    "if not NO_GT:\n",
    "    plot = k3d.plot()\n",
    "\n",
    "    cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "\n",
    "    k3d_points = k3d.points(pred_sampling, point_size=0.03, opacity=0.1, shader='3d', name='sharp_points', color=0xff0000)\n",
    "    plot += k3d_points\n",
    "\n",
    "    plot.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pred_sampling_points(straight_lines,tcks,closed_tcks):\n",
    "    pred_sampling = []\n",
    "\n",
    "    for i in range(len(straight_lines)):\n",
    "        edge = straight_lines[i]\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            pred_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            pred_sampling.append(edge)\n",
    "\n",
    "    for i in range(len(tcks)):\n",
    "        pred_sampling.append(np.array(splev(np.linspace(0,1,5000), tcks[i])).T)\n",
    "\n",
    "    for i in range(len(closed_tcks)):    \n",
    "        pred_sampling.append(np.array(splev(np.linspace(0,1,5000), closed_tcks[i])).T)\n",
    "    return pred_sampling\n",
    "\n",
    "def curve_length(curve,devision_points_count=200):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        curve - curve in as in scipy splprep\n",
    "        devision_points_count - the amount of points on curve\n",
    "    output:\n",
    "        length of the curve\n",
    "    \"\"\"\n",
    "    ar = np.array(splev(np.linspace(0,1,devision_points_count), curve)).T\n",
    "    return np.sum(np.sqrt(np.sum((ar[:-1]-ar[1:])**2,axis=1)))\n",
    "\n",
    "def metric_calculation(pred_sampling,gt_sampling,blur=0.05):\n",
    "  \n",
    "    CD_gt_to_pred = (cKDTree(pred_sampling).query(gt_sampling, 1)[0]**2).mean()\n",
    "    CD_pred_to_gt = (cKDTree(gt_sampling).query(pred_sampling, 1)[0]**2).mean()\n",
    "    \n",
    "    pred_sampling = torch.tensor(pred_sampling)[None]\n",
    "    gt_sampling = torch.tensor(gt_sampling)[None]\n",
    "    chamf_l = chamfer_distance(pred_sampling.clone().cuda().detach().float(), gt_sampling.clone().cuda().detach().float())\n",
    "    \n",
    "    if pred_sampling[0].shape[0]>10000:\n",
    "        sub_idx = pcu.downsample_point_cloud_poisson_disk(np.array(pred_sampling[0]), num_samples=10000)\n",
    "        # Use the indices to get the sample positions and normals\n",
    "        pred_sampling_small = pred_sampling[:,sub_idx]\n",
    "    else:\n",
    "        pred_sampling_small =  pred_sampling\n",
    "    \n",
    "    if gt_sampling[0].shape[0]>10000:\n",
    "        sub_idx = pcu.downsample_point_cloud_poisson_disk(np.array(gt_sampling[0]), num_samples=10000)\n",
    "        # Use the indices to get the sample positions and normals\n",
    "        gt_sampling_small = gt_sampling[:,sub_idx]\n",
    "    else:\n",
    "        gt_sampling_small = gt_sampling\n",
    "    sink_ls, en_ls, gaus_ls, lap_ls = loss_calculating(pred_sampling_small,gt_sampling_small,blur=blur)\n",
    "    return CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls\n",
    "\n",
    "def write_results(folder_name,straight_lines,tcks,closed_tcks):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    with open(folder_name + '/vectorization_line.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(straight_lines, fp)\n",
    "    with open(folder_name+'/vectorization_open_curves.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(tcks, fp)\n",
    "    with open(folder_name+'/vectorization_closed_curves.txt', \"wb\") as fp:   #Pickling\n",
    "        pickle.dump(closed_tcks, fp)\n",
    "        \n",
    "def read_results(folder_name):\n",
    "    with open(folder_name + '/vectorization_line.txt', \"rb\") as fp:   # Unpickling\n",
    "        straight_lines = pickle.load(fp)\n",
    "    with open(folder_name+'/vectorization_open_curves.txt', \"rb\") as fp:   #Pickling\n",
    "        tcks = pickle.load(fp)\n",
    "    with open(folder_name+'/vectorization_closed_curves.txt', \"rb\") as fp:   #Pickling\n",
    "        closed_tcks = pickle.load(fp)\n",
    "    return straight_lines,tcks,closed_tcks\n",
    "\n",
    "def loss_calculating(pred_sampling_small,inp_sampling_small,blur=0.05):\n",
    "    loss = SamplesLoss(loss=\"sinkhorn\",backend = \"tensorized\",blur=blur)\n",
    "    sink_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"energy\",backend = \"tensorized\",blur=blur)\n",
    "    en_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"gaussian\",backend = \"tensorized\",blur=blur)\n",
    "    gaus_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    loss = SamplesLoss(loss=\"laplacian\",backend = \"tensorized\",blur=blur)\n",
    "    lap_ls = loss(pred_sampling_small.cuda(), inp_sampling_small.cuda())\n",
    "\n",
    "    return sink_ls, en_ls, gaus_ls, lap_ls\n",
    "def write_to_file(folder_name, file_name, CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls):\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    with open(folder_name +'/'+'metrics_'+ file_name + '.txt', 'w') as f:\n",
    "        f.write('CD_gt_to_pred')\n",
    "        f.write('\\n')\n",
    "        f.write(str(CD_gt_to_pred.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('CD_pred_to_gt')\n",
    "        f.write('\\n')\n",
    "        f.write(str(CD_pred_to_gt.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Chamfer loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(chamf_l))\n",
    "        f.write('\\n')\n",
    "        f.write('Energy loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(en_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Sinkhorn loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(sink_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Gaussian loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(gaus_ls.item()))\n",
    "        f.write('\\n')\n",
    "        f.write('Laplassian loss')\n",
    "        f.write('\\n')\n",
    "        f.write(str(lap_ls.item()))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Writing metrics and curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "NO_GT=False\n",
    "# load GT curves as segments\n",
    "gt_edges = []\n",
    "if os.path.exists('parametric_labeling/{file}__parametric.txt'.format(file=_id[9:])):\n",
    "    with open('parametric_labeling/{file}__parametric.txt'.format(file=_id[9:])) as f:\n",
    "        for line in f:\n",
    "            curve_id, curve_type, edges = line.split(' ', maxsplit=2)\n",
    "            gt_edges.append(np.array([float(v) for v in edges.split()]).reshape((-1, 2, 3)))\n",
    "else:\n",
    "    NO_GT = True\n",
    "    print('No GT!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sample GT edges\n",
    "if not NO_GT:\n",
    "    gt_sampling = []\n",
    "    for edge in np.concatenate(gt_edges):\n",
    "        num = int(np.linalg.norm(edge[1] - edge[0]) // 0.001)\n",
    "        if num > 0:\n",
    "            linspace = np.linspace(0, 1, num)\n",
    "        #     break\n",
    "            gt_sampling.append(linspace[:,None] * edge[0] + (1 - linspace)[:,None] * edge[1])\n",
    "        else:\n",
    "            gt_sampling.append(edge)\n",
    "    gt_sampling = np.concatenate(gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not NO_GT:\n",
    "    CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls  = metric_calculation(pred_sampling,gt_sampling)\n",
    "    _, _,chamf_l, sink_ls_bl02, en_ls_bl02, gaus_ls_bl02, lap_ls_bl02  = metric_calculation(pred_sampling,gt_sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folder_name = 'pc2wf_res'\n",
    "meta_exp_name = folder_name\n",
    "if not NO_GT:\n",
    "    write_to_file(folder_name+'/metrics/',str(_id),CD_gt_to_pred, CD_pred_to_gt,chamf_l, sink_ls, en_ls, gaus_ls, lap_ls)\n",
    "    df = pd.DataFrame([[str(_id),CD_gt_to_pred.item(),CD_pred_to_gt.item(),chamf_l[0].item(),\n",
    "                        en_ls.item(),sink_ls.item(),\n",
    "                        gaus_ls.item(),lap_ls.item(), en_ls_bl02.item(),sink_ls_bl02.item(),\n",
    "                        gaus_ls_bl02.item(),lap_ls_bl02.item()]],\n",
    "                      index=None,  columns=['Name','CD_gt_to_pred','CD_pred_to_gt','Chamfer_loss',\n",
    "                                            'Energy_loss','Sinkhorn_loss','Gaussian_loss'\n",
    "                                            ,'Laplassian_loss','Energy_loss_blure02','Sinkhorn_loss_blure02','Gaussian_loss_blure02'\n",
    "                                            ,'Laplassian_loss_blure02'])\n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'):\n",
    "        os.makedirs(meta_exp_name+'/metrics/')\n",
    "    \n",
    "    if not os.path.exists(meta_exp_name+'/metrics/'+meta_exp_name + '_final_metrics.csv'):\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_final_metrics.csv', index = False,sep=';')\n",
    "    else:\n",
    "        df.to_csv(meta_exp_name+'/metrics/'+meta_exp_name + '_final_metrics.csv', mode='a', header=None, index = False,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff48aecd5fcd46c5bc003c888a6028a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save this also\n",
    "if not NO_GT:\n",
    "    plot = k3d.plot()\n",
    "\n",
    "    cmap=k3d.colormaps.matplotlib_color_maps.plasma_r\n",
    "\n",
    "    k3d_points = k3d.points(pred_sampling, point_size=0.03, opacity=0.1, shader='3d', name='sharp_points', color=0xff0000)\n",
    "    plot += k3d_points\n",
    "\n",
    "    k3d_points = k3d.points(gt_sampling, point_size=0.03, opacity=0.1, shader='3d', name='sharp_points')\n",
    "    plot += k3d_points\n",
    "\n",
    "    plot.display()\n",
    "    with open(folder_name+'/plot_with_GT/'+str(_id)+'.html', 'w') as f:\n",
    "        f.write(plot.get_snapshot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}